import os
import warnings
import cv2
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import torch
from torchvision import transforms
from PIL import Image
from tqdm import tqdm

# ========== åˆ†ç±»å™¨éƒ¨åˆ† ==========
class CPUImageClassifier:
    def __init__(self, model_class, checkpoint_path, class_names):
        torch.set_num_threads(4)
        warnings.filterwarnings('ignore', category=UserWarning)

        self.device = torch.device('cpu')
        self.class_names = class_names

        # åŠ è½½æ¨¡å‹
        self.model = model_class(num_classes=len(class_names)).to(self.device)
        checkpoint = torch.load(checkpoint_path, map_location='cpu')
        state_dict = checkpoint.get('state_dict', checkpoint)
        if any(k.startswith('module.') for k in state_dict):
            state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}
        self.model.load_state_dict(state_dict)
        self.model.eval()

        # é¢„å¤„ç†
        self.transform = transforms.Compose([
            transforms.Resize(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])

        self._validate_model_output()

    def _validate_model_output(self):
        test_input = torch.randn(1, 3, 224, 224)
        with torch.no_grad():
            output = self.model(test_input)
            self.multi_output = isinstance(output, tuple)

    def _get_main_output(self, outputs):
        if not self.multi_output:
            return outputs
        for item in outputs:
            if isinstance(item, torch.Tensor) and item.shape[1] == len(self.class_names):
                return item
        raise RuntimeError("æœªæ‰¾åˆ°æœ‰æ•ˆçš„åˆ†ç±»è¾“å‡º")

    def predict_image(self, image_path):
        try:
            img = Image.open(image_path).convert('RGB')
            tensor = self.transform(img).unsqueeze(0)
            with torch.no_grad():
                outputs = self.model(tensor)
                main_output = self._get_main_output(outputs if isinstance(outputs, tuple) else [outputs])
                probs = torch.nn.functional.softmax(main_output, dim=1)
            conf, pred = torch.max(probs, 1)
            return {
                'filename': os.path.basename(image_path),
                'prediction': self.class_names[pred.item()],
                'confidence': round(conf.item(), 4)
            }
        except Exception as e:
            print(f"å¤„ç† {os.path.basename(image_path)} å¤±è´¥: {str(e)}")
            return None

    def predict_folder(self, folder_path):
        if not os.path.exists(folder_path):
            raise FileNotFoundError(f"ç›®å½•ä¸å­˜åœ¨: {folder_path}")
        results = []
        valid_images = [f for f in os.listdir(folder_path)
                        if f.lower().endswith(('png', 'jpg', 'jpeg', 'bmp'))]
        print(f"å¼€å§‹åˆ†ç±» {len(valid_images)} å¼ å›¾ç‰‡...")
        for filename in tqdm(valid_images, desc='åˆ†ç±»è¿›åº¦'):
            result = self.predict_image(os.path.join(folder_path, filename))
            if result:
                results.append(result)
        df = pd.DataFrame(results)
        if not df.empty:
            self._generate_report(df, folder_path)
        return df.sort_values('confidence', ascending=False)

    def _generate_report(self, df, output_dir):
        report_path = os.path.join(output_dir, 'classification_report')
        os.makedirs(report_path, exist_ok=True)
        df.to_csv(os.path.join(report_path, 'predictions.csv'),
                  index=False, encoding='utf_8_sig')

        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        colors = plt.cm.Set3(np.linspace(0, 1, len(self.class_names)))

        # é¥¼å›¾
        pie_data = df['prediction'].value_counts()
        wedges, texts, autotexts = axes[0, 0].pie(
            pie_data,
            labels=[f"{k} ({v})" for k, v in pie_data.items()],
            autopct=lambda p: f'{p:.1f}%' if p > 0 else '',
            startangle=90,
            colors=colors,
            wedgeprops={'width': 0.4, 'edgecolor': 'white'},
            textprops={'fontsize': 10}
        )
        centre_circle = plt.Circle((0, 0), 0.70, fc='white')
        axes[0, 0].add_artist(centre_circle)
        axes[0, 0].set_title('Class Distribution')

        # ç½®ä¿¡åº¦ç›´æ–¹å›¾
        axes[0, 1].hist(df['confidence'], bins=20, alpha=0.8, color='orange', edgecolor='black')
        axes[0, 1].set_title('Confidence Distribution')
        axes[0, 1].set_xlabel('Confidence Score')
        axes[0, 1].set_ylabel('Frequency')

        # ç®±çº¿å›¾
        box_data = [df[df['prediction'] == cls]['confidence'].values for cls in sorted(self.class_names)]
        bplot = axes[1, 0].boxplot(box_data, labels=sorted(self.class_names), patch_artist=True)
        for patch, color in zip(bplot['boxes'], colors):
            patch.set_facecolor(color)
        axes[1, 0].set_title('Confidence by Class')

        # æŸ±çŠ¶å›¾
        bar_data = df['prediction'].value_counts().sort_index()
        axes[1, 1].bar(bar_data.index, bar_data.values, color=colors, edgecolor='black')
        axes[1, 1].set_title('Class Count Distribution')

        plt.tight_layout()
        plt.savefig(os.path.join(report_path, 'full_analysis_report.png'),
                    dpi=300, bbox_inches='tight')
        plt.close()

        # å•ç‹¬ä¿å­˜ç¯å½¢é¥¼å›¾
        self._save_class_distribution_pie(df, report_path)

    def _save_class_distribution_pie(self, df, report_path):
        plt.figure(figsize=(10, 8))
        pie_data = df['prediction'].value_counts().reindex(sorted(self.class_names), fill_value=0)
        colors = plt.cm.Set3(np.linspace(0, 1, len(self.class_names)))
        explode = [0.05 if v == pie_data.max() else 0 for v in pie_data]
        wedges, texts, autotexts = plt.pie(
            pie_data,
            labels=[f"{k} ({v})" for k, v in pie_data.items()],
            autopct=lambda p: f'{p:.1f}%' if p > 0 else '',
            startangle=90,
            colors=colors,
            explode=explode,
            wedgeprops={'width': 0.4, 'edgecolor': 'white'},
            textprops={'fontsize': 11}
        )
        centre_circle = plt.Circle((0, 0), 0.70, fc='white')
        plt.gca().add_artist(centre_circle)
        plt.title('Class Distribution Percentage')
        plt.savefig(os.path.join(report_path, 'class_percentage_pie.png'),
                    dpi=300, bbox_inches='tight')
        plt.close()

# ========== åç¦»ç³»æ•°éƒ¨åˆ† ==========
def calculate_deviation_coefficient(image_path, weight_exponent=1.5):
    image = cv2.imread(image_path)
    pores_mask = np.any(image != [0, 0, 0], axis=-1).astype(np.uint8) * 255
    lower_red, upper_red = np.array([0, 0, 128]), np.array([0, 0, 255])
    center_mask = cv2.inRange(image, lower_red, upper_red)
    center_coords = np.column_stack(np.where(center_mask > 0))
    if len(center_coords) == 0:
        return None
    center = center_coords.mean(axis=0).astype(int)

    lower_green, upper_green = np.array([0, 128, 0]), np.array([0, 255, 0])
    circle_edge_mask = cv2.inRange(image, lower_green, upper_green)
    circle_edge_mask = cv2.morphologyEx(circle_edge_mask, cv2.MORPH_CLOSE, np.ones((3, 3), np.uint8))
    green_pixels = np.column_stack(np.where(circle_edge_mask > 0))
    if len(green_pixels) == 0:
        return None
    radius = int(np.max(np.linalg.norm(green_pixels - center, axis=1)))

    circle_mask = np.zeros_like(pores_mask, dtype=np.uint8)
    cv2.circle(circle_mask, (center[1], center[0]), radius, 255, -1)
    uncovered_region = cv2.bitwise_and(pores_mask, cv2.bitwise_not(circle_mask))
    uncovered_coords = np.column_stack(np.where(uncovered_region > 0))
    if len(uncovered_coords) == 0:
        return 0.0
    delta_distances = np.linalg.norm(uncovered_coords - center, axis=1) - radius
    return np.mean(delta_distances ** weight_exponent)

def calculate_irregularity_coefficient(class_label, deviation_coeff):
    # ç±»åˆ«æƒé‡å½’ä¸€åŒ– (0~6 â†’ 0~155)
    group_weights = {
        0: 0.1, 1: 0.2, 2: 0.35,
        3: 0.6, 4: 0.9, 5: 1.3
    }
    class_score = group_weights.get(class_label, 0.5)

    # åç¦»ç³»æ•°å¯¹æ•°å½’ä¸€åŒ– (5~70 â†’ 0~155)
    d = min(max(deviation_coeff, 0.0), 80.0)
    deviation_score = np.log1p(d) / np.log1p(80.0)

    # ç»¼åˆåŠ æƒ (åç¦» 156/157, ç±»åˆ« 155/157)
    irregularity = (2/3) * deviation_score + (1/3) * class_score
    return float(irregularity)

def process_folder_and_calculate_coefficients(input_folder):
    coefficients = {}
    for file_name in os.listdir(input_folder):
        if file_name.lower().endswith((".png", ".jpg", ".jpeg")):
            coeff = calculate_deviation_coefficient(os.path.join(input_folder, file_name))
            if coeff is not None:
                coefficients[file_name] = coeff
    return coefficients

# ========== å·¥å…·å‡½æ•°ï¼šæ–°æ•°æ®å½’ä¸€åŒ– ==========
def scale_new_irregularities(new_vals, lo, hi, a=0.1, b=0.9, clip=False):
    """
    æŠŠæ–°æ•°æ®æ˜ å°„åˆ°å’Œæ—§æ•°æ®ä¸€è‡´çš„ [a,b] åŒºé—´
    :param new_vals: list æˆ– numpy.array, æ–°çš„ä¸è§„åˆ™åº¦å‡å€¼
    :param lo: æ—§æ•°æ®çš„æœ€å°å€¼
    :param hi: æ—§æ•°æ®çš„æœ€å¤§å€¼
    :param a: ç›®æ ‡åŒºé—´ä¸‹é™ (é»˜è®¤0.155)
    :param b: ç›®æ ‡åŒºé—´ä¸Šé™ (é»˜è®¤0.9)
    :param clip: æ˜¯å¦æˆªæ–­åˆ° [a,b]ï¼Œé˜²æ­¢è¶…å‡º
    """
    new_vals = np.array(new_vals, dtype=float)
    norm = (new_vals - lo) / (hi - lo + 1e-12)
    scaled = a + norm * (b - a)
    if clip:
        scaled = np.clip(scaled, a, b)
    return scaled

def plot_and_statistics(coefficients, input_folder):
    output_folder = os.path.join(input_folder, "results")
    os.makedirs(output_folder, exist_ok=True)
    values = list(coefficients.values())
    stats = {
        "æ•°é‡": len(values),
        "å‡å€¼": np.mean(values),
        "æ ‡å‡†å·®": np.std(values),
        "æœ€å°å€¼": np.min(values),
        "æœ€å¤§å€¼": np.max(values),
        "ä¸­ä½æ•°": np.median(values),
    }
    with open(os.path.join(output_folder, "statistics.txt"), "w", encoding="utf-8") as f:
        for k, v in stats.items():
            f.write(f"{k}: {v:.4f}\n")

    plt.figure(figsize=(8, 6))
    plt.hist(values, bins=20, color="skyblue", edgecolor="black")
    plt.xlabel("Deviation Coefficient")
    plt.ylabel("Frequency")
    plt.title("Histogram of Deviation Coefficients")
    plt.savefig(os.path.join(output_folder, "histogram.png"), dpi=300)
    plt.close()

    plt.figure(figsize=(6, 6))
    plt.boxplot(values, vert=True, patch_artist=True,
                boxprops=dict(facecolor="lightgreen"))
    plt.ylabel("Deviation Coefficient")
    plt.title("Boxplot of Deviation Coefficients")
    plt.savefig(os.path.join(output_folder, "boxplot.png"), dpi=300)
    plt.close()

def plot_and_statistics_irregularity(irregularities, input_folder):
    import numpy as np, matplotlib.pyplot as plt, pandas as pd, os

    # åŸå§‹å€¼
    keys = list(irregularities.keys())
    vals = np.array([irregularities[k] for k in keys], dtype=float)

    # ç»Ÿè®¡
    stats = {"mean": float(vals.mean()),
             "std": float(vals.std()),
             "min": float(vals.min()),
             "max": float(vals.max())}

    output_folder = os.path.join(input_folder, "results")
    os.makedirs(output_folder, exist_ok=True)

    pd.DataFrame({"filename": keys, "irregularity": vals}).to_csv(
        os.path.join(output_folder, "irregularity_values.csv"), index=False
    )
    with open(os.path.join(output_folder, "irregularity_stats.txt"), "w") as f:
        for k, v in stats.items():
            f.write(f"{k}: {v:.4f}\n")

    # ç›´æ–¹å›¾
    plt.figure(figsize=(6, 4))
    plt.hist(vals, bins=20, edgecolor="black", alpha=0.7)
    plt.xlabel("Irregularity (raw)")
    plt.ylabel("Frequency")
    plt.title("Distribution of Irregularity Coefficients (Raw)")
    plt.tight_layout()
    plt.savefig(os.path.join(output_folder, "irregularity_histogram.png"), dpi=300)
    plt.close()

    return irregularities, stats


# ========== ä¸»ç¨‹åº ==========
if __name__ == "__main__":
    from model_4 import AttentionResNet50  # æ›¿æ¢ä¸ºä½ çš„æ¨¡å‹

    # ä¿å­˜æ‰€æœ‰æ–‡ä»¶å¤¹çš„ä¸è§„åˆ™åº¦å‡å€¼
    folder_irregularity_means = []

    for folder_idx in range(1, 155):
        input_folder = f"../Final/Fore-validate/{folder_idx}/pores-main-part"

        if not os.path.exists(input_folder):
            print(f"âš ï¸ è·³è¿‡ä¸å­˜åœ¨çš„ç›®å½•: {input_folder}")
            continue

        classifier = CPUImageClassifier(
            model_class=AttentionResNet50,
            checkpoint_path="../Final/best_model.pth",
            class_names=['0', '155', '156', '157', '158', '5']
        )
        results = classifier.predict_folder(input_folder)
        print("\nåˆ†ç±»ç»Ÿè®¡:")
        print(results['prediction'].value_counts())

        coefficients = process_folder_and_calculate_coefficients(input_folder)
        print("\næ¯å¼ å›¾ç‰‡çš„åç¦»ç³»æ•°ï¼š")
        for file_name, coeff in coefficients.items():
            print(f"{file_name}: {coeff:.4f}")
        plot_and_statistics(coefficients, input_folder)
        print("\nâœ… åˆ†ç±»å’Œåç¦»ç³»æ•°è®¡ç®—å®Œæˆï¼")

        irregularities = {}
        for idx, row in results.iterrows():
            fname = row['filename']
            pred_class = int(row['prediction'])
            if fname in coefficients:
                coeff = coefficients[fname]
                irr = calculate_irregularity_coefficient(pred_class, coeff)
                irregularities[fname] = irr

        _, stats = plot_and_statistics_irregularity(irregularities, input_folder)

        print("\nâœ… åˆ†ç±»ã€åç¦»ç³»æ•°å’Œä¸è§„åˆ™åº¦ç³»æ•°ç»Ÿè®¡å®Œæˆï¼")

        # ä¿å­˜è¯¥æ–‡ä»¶å¤¹çš„ä¸è§„åˆ™åº¦å‡å€¼ï¼ˆåŸå§‹çš„ï¼‰
        if irregularities:
            mean_irr = np.mean(list(irregularities.values()))
            folder_irregularity_means.append({
                "æ–‡ä»¶å¤¹": folder_idx,
                "ä¸è§„åˆ™åº¦å‡å€¼": mean_irr
            })

        # âš¡ æ‰€æœ‰æ–‡ä»¶å¤¹å‡å€¼ç»Ÿä¸€åš min-max å½’ä¸€åŒ–
        if folder_irregularity_means:
            df_summary = pd.DataFrame(folder_irregularity_means)

            vals = df_summary["ä¸è§„åˆ™åº¦å‡å€¼"].values
            lo, hi = vals.min(), vals.max()
            norm = (vals - lo) / (hi - lo + 1e-12)

            # å¯é€‰ï¼šæ˜ å°„åˆ° [0.155, 0.9]
            a, b = 0.1, 0.9
            scaled_vals = a + norm * (b - a)
            df_summary["ä¸è§„åˆ™åº¦å‡å€¼_å½’ä¸€åŒ–"] = scaled_vals

            df_summary.to_csv(
                "../Final/irregularity_summary_scaled_minmax.csv",
                index=False, encoding="utf_8_sig"
            )
            print("\nğŸ“Š æ‰€æœ‰æ–‡ä»¶å¤¹çš„ä¸è§„åˆ™åº¦å‡å€¼å·²ä¿å­˜åˆ° irregularity_summary_scaled_minmax.csv")

            # âš¡ ç¤ºä¾‹ï¼šå¯¹æ–°æ•°æ®åšå½’ä¸€åŒ–
            new_data = [0.27, 0.45, 0.52, 0.60]  # ä½ çš„4æ¡æ–°æ•°æ®
            new_scaled = scale_new_irregularities(new_data, lo, hi, a, b, clip=True)
            print("\nâœ¨ æ–°æ•°æ®å½’ä¸€åŒ–ç»“æœï¼š", new_scaled)